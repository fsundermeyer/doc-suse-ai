<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head><title>Maintaining Data Integrity of AI Applications</title><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"/><link rel="stylesheet" type="text/css" href="static/css/style.css"/>
<link rel="schema.dc" href="http://purl.org/dc/elements/1.1/"/><link rel="schema.dcterms" href="http://purl.org/dc/terms/"/>
<meta name="dcterms.modified" content="2025-12-02"/><meta name="dcterms.created" content="2025-12-02"/><meta name="title" content="Maintaining Data Integrity of AI Applications"/>
<meta name="description" content="Copyright© 2006– SUSE LLC and contributors. All rights reserved."/>
<meta name="book-title" content="Maintaining Data Integrity of AI Applications"/>
<meta name="publisher" content="SUSE"/><meta property="og:title" content="Maintaining Data Integrity of AI Applications"/>
<meta property="og:description" content="Copyright© 2006– SUSE LLC and contributors. All rights rese…"/>
<meta property="og:type" content="article"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Maintaining Data Integrity of AI Applications"/>
<meta name="twitter:description" content="Copyright© 2006– SUSE LLC and contributors. All rights rese…"/>
<script type="application/ld+json">{
    "@context": "http://schema.org",
    "@type": ["TechArticle"],
    "image": "https://www.suse.com/assets/img/suse-white-logo-green.svg",
    
     "isPartOf": {
      "@type": "CreativeWorkSeries",
      "name": "Products &amp; Solutions"
    },
    
    "inLanguage": "en",
    

    "headline": "Maintaining Data Integrity of AI Applications",
  
    "description": "Maintaining Data Integrity of AI Applications",
      
    "author": [
      {
        "@type": "Corporation",
        "name": "SUSE Product &amp; Solution Documentation Team",
        "url": "https://www.suse.com/assets/img/suse-white-logo-green.svg"
      }
    ],
      
    "dateModified": "2025-12-02T00:00+02:00",
      
    "datePublished": "2025-12-02T00:00+02:00",
      

    "about": [
      
    ],
  
    "sameAs": [
          "https://www.facebook.com/SUSEWorldwide/about",
          "https://www.youtube.com/channel/UCHTfqIzPKz4f_dri36lAQGA",
          "https://twitter.com/SUSE",
          "https://www.linkedin.com/company/suse"
    ],
    "publisher": {
      "@type": "Corporation",
      "name": "SUSE",
      "url": "https://documentation.suse.com",
      "logo": {
        "@type": "ImageObject",
        "url": "https://www.suse.com/assets/img/suse-white-logo-green.svg"
      }
    }
  }</script>
<link rel="next" href="id-glossary.html" title="Glossary"/><link type="text/css" rel="preload" as="style" onload="this.rel='stylesheet'" href="https://documentation.suse.com/docserv/res/fonts/suse/suse.css"/><script src="static/js/script-purejs.js" type="text/javascript"> </script><script src="static/js/highlight.js" type="text/javascript"> </script><script>hljs.highlightAll();</script></head><body class="wide offline js-off"><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-pagination">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><header id="_mainnav"><div class="growth-inhibitor"><img src="static/images/logo.svg" alt="Logo" class="logo"/></div></header><div class="crumbs"><div class="growth-inhibitor"><a class="crumb" href="index.html">Maintaining Data Integrity of AI Applications</a></div></div><main id="_content"><nav id="_side-toc-overall" tabindex="0" class="side-toc"><div class="side-title">Maintaining Data Integrity of AI Applications</div> </nav><button id="_open-side-toc-overall" title="Contents"> </button><article class="documentation"><button id="_unfold-side-toc-page">On this page</button><section xml:lang="en" class="article" id="id-1" data-id-title="Maintaining Data Integrity of AI Applications"><div class="titlepage"><div><div><div class="title-container"><h1 class="title">Maintaining Data Integrity of AI Applications <a title="Permalink" class="permalink" href="index.html#">#</a></h1><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div><div class="date"><span class="imprint-label">Publication Date: </span>2025-12-02</div></div></div><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.1"><span class="term">WHAT?</span></dt><dd><p>Maintaining the security of the entire AI stack environment.</p></dd><dt id="id-1.3.2"><span class="term">WHY?</span></dt><dd><p>To learn how to prevent data leaks and maintain the correct
functioning of your AI application.</p></dd><dt id="id-1.3.3"><span class="term">EFFORT</span></dt><dd><p>Understanding the security threats and safety measures for
running AI services requires less than 30 minutes of your time.</p></dd><dt id="id-1.3.4"><span class="term">GOAL</span></dt><dd><p>Understand how attackers can exploit your AI stack to access
sensitive data and learn safety techniques to prevent such
attacks.</p></dd></dl></div><section class="sect1" id="ai_data_integrity_maintaining" data-id-title="Maintaining data integrity of AI applications"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">1 </span><span class="title-name">Maintaining data integrity of AI applications</span></span> <a title="Permalink" class="permalink" href="index.html#ai_data_integrity_maintaining">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><section class="sect2" id="_why_care_about_ai_security" data-id-title="Why care about the security of AI applications?"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.1 </span><span class="title-name">Why care about the security of AI applications?</span></span> <a title="Permalink" class="permalink" href="index.html#_why_care_about_ai_security">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>AI applications use AI-driven chatbots to interact with users.
These chatbots are powered by large language models (LLMs) and can process external data sources (RAGs). Such applications are prone to cyber attacks as any other software solutions.
Attackers may impersonate users and apply a series of techniques to steal data and to corrupt the responses provided by AI models.</p></section><section class="sect2" id="ai_components_prone_to_attacks" data-id-title="Which SUSE AI components are prone to attacks"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.2 </span><span class="title-name">Which SUSE AI components are prone to attacks</span></span> <a title="Permalink" class="permalink" href="index.html#ai_components_prone_to_attacks">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Users interact with SUSE AI via the Open WebUI user interface.
With Open WebUI, you can manage users, permissions, AI models, knowledge bases, and chat interactions.
The following SUSE AI components are the most susceptible to security attacks:</p><div class="variablelist"><dl class="variablelist"><dt id="id-1.4.3.3.1"><span class="term">Open WebUI</span></dt><dd><p>Open WebUI enables you to specify external data sources to improve responses.
On a user level, you can append documents directly to the chat input field.
With administrator privileges, you can upload documents to create a knowledge base that enhances the AI model.
The knowledge base acts as a domain-specific augmentation tool for the LLM.
It prevents chatbot hallucination and improves the model’s responses with accurate and up-to-date information.</p><div id="id-1.4.3.3.1.2.2" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><div class="admon-title">Tip</div><p>Actions performed by users—both the administrators and guests—are recorded in an audit log.
With the audit log, it is possible to map all actions that took the system to its current state.</p></div></dd><dt id="id-1.4.3.3.2"><span class="term">Milvus</span></dt><dd><p>It is possible to input documents directly into Milvus—the vector database responsible for the low-level implementation of the knowledge base concept.
Although the user interaction normally takes place via Open WebUI, attackers may bypass Open WebUI to interact with Milvus. This can happen if no identity access management (IAM) policy is controlling database access.</p></dd><dt id="id-1.4.3.3.3"><span class="term">Ollama</span></dt><dd><p>Ollama manages the interactions with several LLMs.
It can search, download, start and manage models within a unified interface.
Ollama does not offer authentication and authorization by default.
Therefore, Ollama’s API should not be exposed without a an element providing IAM capabilities.
In SUSE AI, user interacts with Ollama via Open WebUI, which is able to configure and secure Ollama.</p></dd></dl></div></section><section class="sect2" id="ai_attacks_and_risks" data-id-title="What are common attacks and security risks?"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.3 </span><span class="title-name">What are common attacks and security risks?</span></span> <a title="Permalink" class="permalink" href="index.html#ai_attacks_and_risks">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>This section lists several attacks and security risks related to AI applications.</p><div class="variablelist"><dl class="variablelist"><dt id="id-1.4.4.3.1"><span class="term">RAG poisoning</span></dt><dd><p>A common exploit when a knowledge base—often a vector database—that provides a context for AI model responses is corrupted by the addition of misleading, false or even harmful content.
The malicious documents tend to be crafted specifically to provide wrong answers for a set of user prompts.
This kind of attack usually requires access to a user with privileges to configure the whole platform or the vector databases that support the platform.</p></dd><dt id="id-1.4.4.3.2"><span class="term">Facilitated data exploits</span></dt><dd><p>RAG-powered models can search knowledge bases, summarize content and provide references.
Attackers may use these characteristics to discover and retrieve organizational data with simple prompts instead of relying on more refined data-exploitation techniques.</p></dd><dt id="id-1.4.4.3.3"><span class="term">Prompt leaks</span></dt><dd><p>User prompts may contain sensitive data, so chat caches and system logs need to be protected against attackers.</p></dd></dl></div></section><section class="sect2" id="ai_safety_measures" data-id-title="What safety measures should my organization follow?"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.4 </span><span class="title-name">What safety measures should my organization follow?</span></span> <a title="Permalink" class="permalink" href="index.html#ai_safety_measures">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>To avoid having your system corrupted, there are a few security measures that need to be properly implemented.
Open WebUI and Milvus allow high level user access configurations.
Besides these high level configurations, provide access management with low level network configurations.
To verify that your whole AI stack is secure, consider the following points:</p><div class="variablelist"><dl class="variablelist"><dt id="id-1.4.5.3.1"><span class="term">Adopt strong IAM policies.</span></dt><dd><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>At the authentication level, limit the creation of guest users.</p></li><li class="listitem"><p>At the authorization level, never allow new users to be automatically set as system administrators.</p></li><li class="listitem"><p>Limit the number of users with privileges for adding documents to your knowledge base.</p></li><li class="listitem"><p>Keep in mind that the same policies set for Open WebUI need to be propagated in all systems composing the AI stack.</p></li><li class="listitem"><p>Limit the exposure of internal services (such as Milvus and Ollama) to the Internet.</p></li><li class="listitem"><p>Configure authentication and authorization for all components of the AI stack.</p></li></ul></div></dd><dt id="id-1.4.5.3.2"><span class="term">Adopt an audit log review policy.</span></dt><dd><p>Periodically check the audit logs provided in the Web interface, from both the chatbot and the vector databases.
Look for abnormal behavior from one or more users.</p></dd><dt id="id-1.4.5.3.3"><span class="term">Set up retention policies.</span></dt><dd><p>Avoid saving chat prompts and system logs.</p></dd><dt id="id-1.4.5.3.4"><span class="term">Train users to avoid LLM overreliance.</span></dt><dd><p>Encourage users to approach the answers from the RAG-based models with a critical mindset.
Make sure they are able to verify the references provided by the AI chatbot.
Files used in the context of a user prompt are appended to the AI model’s answer.</p></dd><dt id="id-1.4.5.3.5"><span class="term">Facilitate incident reports.</span></dt><dd><p>Educate your users about how to report problems with the AI model’s answers.
Assign responsibilities for the system support.</p></dd><dt id="id-1.4.5.3.6"><span class="term">Ensure fast action against attacks.</span></dt><dd><p>Remember that when a security breach happens, the sooner the system is restored to a trusted state, the less damage your organization takes.</p></dd><dt id="id-1.4.5.3.7"><span class="term">Set up a secure environment for your applications.</span></dt><dd><p>Make sure that there are components enforcing authentication and authorization rules over the whole installation of the AI Stack.
We do not recommend exposing Milvus and Ollama without proper network configurations.</p></dd></dl></div></section><section class="sect2" id="ai_data_integrity_formoreinfo" data-id-title="For more information"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.5 </span><span class="title-name">For more information</span></span> <a title="Permalink" class="permalink" href="index.html#ai_data_integrity_formoreinfo">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>The article at <a class="link" href="https://cloudsecurityalliance.org/blog/2023/11/22/mitigating-security-risks-in-retrieval-augmented-generation-rag-llm-applications" target="_blank">https://cloudsecurityalliance.org/blog/2023/11/22/mitigating-security-risks-in-retrieval-augmented-generation-rag-llm-applications</a> includes a comprehensive overview of security controls.</p></li><li class="listitem"><p>Specifying external data sources to the AI model knowledge base is described in link:https://documentation.suse.com/suse-ai/1.0/html/openwebui-using/index.html#openwebui-chat-input-field-usage.</p></li></ul></div></section></section><section class="sect1" id="legal_disclaimer" data-id-title="Legal Notice"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">2 </span><span class="title-name">Legal Notice</span></span> <a title="Permalink" class="permalink" href="index.html#legal_disclaimer">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Copyright© 2006–
SUSE LLC and contributors.
All rights reserved.</p><p>Permission is granted to copy, distribute and/or modify this document under the terms of the GNU Free Documentation License, Version 1.2 or (at your option) version 1.3; with the Invariant Section being this copyright notice and license.
A copy of the license version 1.2 is included in the section entitled <span class="quote">“<span class="quote">GNU Free Documentation License</span>”</span>
.</p><p>For SUSE trademarks, see <a class="link" href="https://www.suse.com/company/legal/" target="_blank">https://www.suse.com/company/legal/</a>.
All other third-party trademarks are the property of their respective owners.
Trademark symbols (®, ™ etc.) denote trademarks of SUSE and its affiliates.
Asterisks (*) denote third-party trademarks.</p><p>All information found in this book has been compiled with utmost attention to detail.
However, this does not guarantee complete accuracy.
Neither SUSE LLC, its affiliates, the authors, nor the translators shall be held liable for possible errors or the consequences thereof.</p></section></section><nav class="bottom-pagination"><div> </div><div><a class="pagination-link next" href="id-glossary.html"><span class="pagination-relation">Next</span><span class="pagination-label">Glossary</span></a> </div></nav></article><aside id="_side-toc-page" class="side-toc"><div class="side-title">On this page</div><div class="toc"><ul><li><span class="section"><a href="index.html#ai_data_integrity_maintaining"><span class="title-number">1 </span><span class="title-name">Maintaining data integrity of AI applications</span></a></span><ul><li><span class="section"><a href="index.html#_why_care_about_ai_security"><span class="title-number">1.1 </span><span class="title-name">Why care about the security of AI applications?</span></a></span></li><li><span class="section"><a href="index.html#ai_components_prone_to_attacks"><span class="title-number">1.2 </span><span class="title-name">Which SUSE AI components are prone to attacks</span></a></span></li><li><span class="section"><a href="index.html#ai_attacks_and_risks"><span class="title-number">1.3 </span><span class="title-name">What are common attacks and security risks?</span></a></span></li><li><span class="section"><a href="index.html#ai_safety_measures"><span class="title-number">1.4 </span><span class="title-name">What safety measures should my organization follow?</span></a></span></li><li><span class="section"><a href="index.html#ai_data_integrity_formoreinfo"><span class="title-number">1.5 </span><span class="title-name">For more information</span></a></span></li></ul></li><li><span class="section"><a href="index.html#legal_disclaimer"><span class="title-number">2 </span><span class="title-name">Legal Notice</span></a></span></li><li><span class="glossary"><a href="id-glossary.html"><span class="title-name">Glossary</span></a></span></li><li><span class="appendix"><a href="id-copyright.html"><span class="title-number">A </span><span class="title-name">Copyright</span></a></span></li><li><span class="appendix"><a href="id-gnu-free-documentation-license.html"><span class="title-number">B </span><span class="title-name">GNU Free Documentation License</span></a></span><ul><li><span class="section"><a href="id-gnu-free-documentation-license.html#id-0-preamble"><span class="title-number">B1 </span><span class="title-name">0. PREAMBLE</span></a></span></li><li><span class="section"><a href="id-gnu-free-documentation-license.html#id-1-applicability-and-definitions"><span class="title-number">B2 </span><span class="title-name">1. APPLICABILITY AND DEFINITIONS</span></a></span></li><li><span class="section"><a href="id-gnu-free-documentation-license.html#id-2-verbatim-copying"><span class="title-number">B3 </span><span class="title-name">2. VERBATIM COPYING</span></a></span></li><li><span class="section"><a href="id-gnu-free-documentation-license.html#id-3-copying-in-quantity"><span class="title-number">B4 </span><span class="title-name">3. COPYING IN QUANTITY</span></a></span></li><li><span class="section"><a href="id-gnu-free-documentation-license.html#id-4-modifications"><span class="title-number">B5 </span><span class="title-name">4. MODIFICATIONS</span></a></span></li><li><span class="section"><a href="id-gnu-free-documentation-license.html#id-5-combining-documents"><span class="title-number">B6 </span><span class="title-name">5. COMBINING DOCUMENTS</span></a></span></li><li><span class="section"><a href="id-gnu-free-documentation-license.html#id-6-collections-of-documents"><span class="title-number">B7 </span><span class="title-name">6. COLLECTIONS OF DOCUMENTS</span></a></span></li><li><span class="section"><a href="id-gnu-free-documentation-license.html#id-7-aggregation-with-independent-works"><span class="title-number">B8 </span><span class="title-name">7. AGGREGATION WITH INDEPENDENT WORKS</span></a></span></li><li><span class="section"><a href="id-gnu-free-documentation-license.html#id-8-translation"><span class="title-number">B9 </span><span class="title-name">8. TRANSLATION</span></a></span></li><li><span class="section"><a href="id-gnu-free-documentation-license.html#id-9-termination"><span class="title-number">B10 </span><span class="title-name">9. TERMINATION</span></a></span></li><li><span class="section"><a href="id-gnu-free-documentation-license.html#id-1-future-revisions-of-this-license"><span class="title-number">B11 </span><span class="title-name">1. FUTURE REVISIONS OF THIS LICENSE</span></a></span></li><li><span class="section"><a href="id-gnu-free-documentation-license.html#id-addendum-how-to-use-this-license-for-your-documents"><span class="title-number">B12 </span><span class="title-name">ADDENDUM: How to use this License for your documents</span></a></span></li></ul></li></ul></div><div class="side-title">Share this page</div><ul class="share"><li><a id="_share-mail" href="#" title="E-Mail"> </a></li><li><a id="_print-button" href="#" title="Print this page"> </a></li></ul> </aside></main><footer id="_footer"><div class="growth-inhibitor"><div class="copy"><span class="copy__rights">© SUSE  2025</span></div></div></footer>
<script type="text/javascript" src="static/js/language-switcher.js"> </script></body></html>
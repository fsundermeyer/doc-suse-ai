[#ailibrary-installing-deployer]
= Installing {ailibrary} components using {saideployer}

{saideployer} consists of a meta {helm} chart that takes care of downloading and installing individual {ailibrary} components required by {productname} on a {kube} cluster.

The following procedure describes how to customize and use the {saideployer} to install {ailibrary} components.
It assumes that you already completed steps described in xref:suse-ai-deploy-suse-ai[] including the installation of {certmanager}.

. Pull the {saideployer} {helm} chart with the relevant chart version and untar it.
You can find the latest of the chart on the {sappco} page at link:https://apps.rancher.io/applications/suse-ai-deployer[].
[source,subs="+attributes"]
----
{prompt_user}helm pull oci://dp.apps.rancher.io/charts/suse-ai-deployer \
  --version 1.0.0 --untar
{prompt_user}cd suse-ai-deployer
----
. Inspect the downloaded chart and its default values.
[source,subs="+attributes"]
----
{prompt_user}helm show chart .
{prompt_user}helm show values .
----
[TIP]
====
To see default values for the charts of the individual components within the meta chart, run the following commands.
[source,subs="+attributes"]
----
{prompt_user}helm show values charts/ollama/
{prompt_user}helm show values charts/open-webui/
{prompt_user}helm show values charts/milvus/
{prompt_user}helm show values charts/pytorch
----
====
. Explore downloaded example override files in the `suse-ai-deployer/examples` subdirectory.
It typically includes the following files:
`suse-gen-ai-minimal.yaml`:: Basic configuration to get started with GenAI. It deploys {ollama} without GPU support, {owui}, and {milvus} in stand-alone mode using local storage. {pytorch} is disabled.
`suse-gen-ai.yaml`:: Configuration optimized for production usage. It deploys {ollama} with GPU support, {owui}, and {milvus} in cluster mode using Longhorn storage. {pytorch} is disabled.
`suse-ml-stack.yaml`:: Basic configuration that enables deployment of {pytorch} with no GPU support with Longhorn storage. It deploys {pytorch} but disables {ollama}, {owui} and {milvus}.
. Create `custom-overrides.yaml` override file based one of the above examples.
The examples use self-signed certificates for TLS communication.
To use other option (see xref:owui-tls-sources[]), copy the `global` section from the `values.yaml` file into your `custom-overrides.yaml` and update its `tls` section as needed.
. Install the {saideployer} {helm} chart with while overriding values from the `custom-overrides.yaml` file.
Use the appropriate `RELEASE_NAME` and `SUSE_AI_NAMESPACE` based the configuration in `custom-overrides.yaml`.
[source,subs="+attributes"]
----
{prompt_user}helm upgrade --install \
  RELEASE_NAME \
  --namespace  SUSE_AI_NAMESPACE \
  --create-namespace \
  --values ./custom-overrides.yaml \
  --version 1.0.0 \
  oci://dp.apps.rancher.io/charts/suse-ai-deployer
----

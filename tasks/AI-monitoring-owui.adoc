[[ai-monitoring-owui]]
= Monitoring {owui}

The preferred way of retrieving relevant telemetry data from {owui} is to use the https://github.com/SUSE/suse-ai-observability-extension/blob/main/integrations/oi-filter/suse_ai_filter.py[{productname}
        Filter].
It requires enabling and configuring {owui} Pipelines. 

[[ai-monitoring-owui-pipelines-cmdline]]
.Procedure: Configuring pipeline filter during {owui} installation (recommended)
. Verify that the {owui} installation override file [path]``owui_custom_overrides.yaml`` includes the following content. 
+

----
pipelines:
  enabled: true
  persistence:
    storageClass: longhorn <1>
  extraEnvVars: <2>
    - name: PIPELINES_URLS <3>
      value: "https://raw.githubusercontent.com/SUSE/suse-ai-observability-extension/refs/heads/main/integrations/oi-filter/suse_ai_filter.py"
    - name: OTEL_SERVICE_NAME <4>
      value: "Open WebUI"
    - name: OTEL_EXPORTER_HTTP_OTLP_ENDPOINT <5>
      value: "http://opentelemetry-collector.suse-observability.svc.cluster.local:4318"
    - name: PRICING_JSON <6>
      value: "https://raw.githubusercontent.com/SUSE/suse-ai-observability-extension/refs/heads/main/integrations/oi-filter/pricing.json"
extraEnvVars:
- name: OPENAI_API_KEY <7>
  value: "0p3n-w3bu!"
----
+
NOTE: In the above example, there are two `extraEnvVars` blocks: one at the root level and another inside the `pipelines` configuration.
The root-level `extraEnvVars` is fed into {owui} to configure the communication between {owui} and {owui} Pipelines.
The `extraEnvVars` inside the configuration are injected into the container that acts as a runtime for the ``pipelines``. 
+

+
<1>
            ` longhorn` or ``local-path``.
          
<2>
            The environment variables that you are making available for the
            pipeline's runtime container.
          
<3>
            A list of pipeline URLs to be downloaded and installed by default.
            Individual URLs are separated by a semicolon ``;`` .
          
            For air-gapped deployments, you need to provide the pipelines at
            URLs that are accessible from the local host, such as an internal
            GitLab instance.
          
<4>
            The service name that appears in traces and topological
            representations in {sobservability}.
          
<5>
            The endpoint for the {otelemetry} collector. Make sure to use the
            HTTP port of your collector.
          
<6>
            A file for the model multipliers in cost estimation. You can
            customize it to match your actual infrastructure experimentally.
          

            For air-gapped deployments, you need to provide the pipelines at
            URLs that are accessible from the local host, such as an internal
            GitLab instance.
          
<7>
            The value for the API key between {owui} and {owui} Pipelines. The
            default value is '0p3n-w3bu!' .
          
. After you fill the override file with correct values, install or update {owui}. 
+

----
> helm upgrade \
  --install open-webui oci://dp.apps.rancher.io/charts/open-webui \
  -n SUSE_AI_NAMESPACE \
  --create-namespace \
  --version 7.2.0 \
  -f owui_custom_overrides.yaml 
----
+
TIP: Make sure to set the version, namespace and other options to the proper values. 
+


+
After the installation is successful, you can access tracing data in {sobservability} for each chat. 
+
TIP: You can verify that a new connection was created with correct credentials in menu:Admin
          Panel[Settings > Connections]. 

.New connection added for the pipeline [[_fg_pipeline_connection]]
image::ai-observability-connection.png["Connections settings page within an admin panel, highlighting a newly added Ollama API connection with its URL and an active status",scaledwidth=75%]

+

[[ai-monitoring-owui-pipelines-webui]]
.Procedure: Configuring a pipeline filter in {owui} (recommended)

If you already have a running instance of {owui} with the pipelines enabled and configured, you can set up the {productname} Filter in its Web user interface. 

.Requirements
** {empty}
+

include::../snippets/openwebui-requirement-admin-privileges.adoc[leveloffset=1]
. In the bottom left of the {owui} window, click your avatar icon to open the user menu and select menu:Admin Panel[] . 
. Click the menu:Settings[] tab and select menu:Pipelines[] from the left menu. 
. In the menu:Install from Github URL[] section, enter `https://raw.githubusercontent.com/SUSE/suse-ai-observability-extension/refs/heads/main/integrations/oi-filter/suse_ai_filter.py` and click the upload button on the right to upload the pipeline from the URL. 
. After the upload is finished, you can review the configuration of the pipeline. Confirm with menu:Save[] . 
+

.Adding {suseai} filter pipeline [[_fig_ai_monitoring_owui_pipelines_webui]]

image::ai-observability-filter-pipeline.png[Screenshot showing the detailed configuration and code content for a {suseai} filter pipeline,scaledwidth=100%]

[[ai-monitoring-owui-default-metrics]]
.Procedure: Configuring default {owui} metrics and traces (advanced)

{owui} also offers certain built-in {otelemetry} integration for traces and metrics.
These signals are related to the API consumption but do not provide details about the GenAI monitoring.
That is why we need to configure the {productname} filter as described in 

. Append the following environment variables to your `extraEnvVars` section in the [path]``owui_custom_overrides.yaml`` file mentioned in. 
+

----
[...]
extraEnvVars:
- name: OPENAI_API_KEY
  value: "0p3n-w3bu!"
- name: ENABLE_OTEL
  value: "true"
- name: ENABLE_OTEL_METRICS
  value: "true"
- name: OTEL_EXPORTER_OTLP_INSECURE
  value: "false" <8>
- name: OTEL_EXPORTER_OTLP_ENDPOINT
  value:`CUSTOM_OTEL_ENDPOINT` <9>
- name: OTEL_SERVICE_NAME
  value:`CUSTOM_OTEL_IDENTIFYER` <10>
----
+
<8>
            Set to 'true' for testing or controlled environments, and 'false' for production
            deployments with TLS communication.
          
<9>
            Enter your custom {otelemetry} collector endpoint URL, such as
            ``"http://opentelemetry-collector.suse-observability.svc.cluster.local:4318"``.
          
<10>
            Specify a custom identifier for the {otelemetry} service, such as
            ``"OI Core""``.
          
. Save the enhanced override file and update {owui}: 
+

----
> helm upgrade \
  --install open-webui oci://dp.apps.rancher.io/charts/open-webui \
  -n SUSE_AI_NAMESPACE \
  --create-namespace \
  --version 7.2.0 \
  -f owui_custom_overrides.yaml 
----
